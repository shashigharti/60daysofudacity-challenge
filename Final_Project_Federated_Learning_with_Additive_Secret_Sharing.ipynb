{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final Project - Federated Learning with Additive Secret Sharing.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shashigharti/60daysofudacity-challenge/blob/master/Final_Project_Federated_Learning_with_Additive_Secret_Sharing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0zzKhh5mwlQW",
        "colab_type": "text"
      },
      "source": [
        "**Project**\n",
        "Federated Learning with Trusted Aggregator ;\n",
        "Aggregate gradients using additive secret sharing and fixed precision encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_zsoMXPPT3Xj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install syft"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRtdnRRXcbxk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "622f7977-9887-4d28-995a-241a197d6c9e"
      },
      "source": [
        "hook = sy.TorchHook(th)\n"
      ],
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0711 11:17:05.043093 139749766735744 hook.py:98] Torch was already hooked... skipping hooking process\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Inwvj75TLKD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import syft as sy\n",
        "import torch as th\n",
        "from torch import nn, optim\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aGR_-YPvc78-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2780f256-5e01-43a1-f0ed-bff0910b3a06"
      },
      "source": [
        "hook"
      ],
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<syft.frameworks.torch.hook.hook.TorchHook at 0x7f196c4bc9b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1n9pgRzpThCo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#create three workers\n",
        "bob = sy.VirtualWorker(hook, id=\"bob\")\n",
        "alice = sy.VirtualWorker(hook, id=\"alice\")\n",
        "secure_worker = sy.VirtualWorker(hook, id=\"secure_worker\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wRSuRHidP-v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bob = bob.clear_objects()\n",
        "alice = alice.clear_objects()\n",
        "secure_worker = secure_worker.clear_objects()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bC20z4seV5-k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = th.tensor([[0,0],[0,1],[1,0],[1,1.]])\n",
        "target = th.tensor([[0],[0],[1],[1.]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rdSkc-0H_1Xz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#initialize a toy model\n",
        "# A Toy Model\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc1 = nn.Linear(2, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        return x\n",
        "model = Net()\n",
        "\n",
        "#initialize a toy model\n",
        "model = nn.Linear(2,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dMhFt3iH_JSv",
        "colab_type": "code",
        "outputId": "d2b1a040-3cba-4b00-a6dc-c1239c61f0bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "# Encode everything\n",
        "data = data.fix_prec().share(bob, alice, crypto_provider=secure_worker, requires_grad=True)\n",
        "target = target.fix_prec().share(bob, alice, crypto_provider=secure_worker, requires_grad=True)\n",
        "model = model.fix_precision().share(bob, alice, crypto_provider=secure_worker, requires_grad=True)\n",
        "print(data)\n"
      ],
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(Wrapper)>AutogradTensor>FixedPrecisionTensor>(Wrapper)>[AdditiveSharingTensor]\n",
            "\t-> (Wrapper)>[PointerTensor | me:64826375887 -> bob:23175403454]\n",
            "\t-> (Wrapper)>[PointerTensor | me:58331535930 -> alice:4228534626]\n",
            "\t*crypto provider: secure_worker*\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "93BZeg4YXZv1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        },
        "outputId": "157259da-ae3d-4efa-b4e3-263d9687285c"
      },
      "source": [
        "opt = optim.SGD(params=model.parameters(),lr=0.1).fix_precision()\n",
        "\n",
        "for iter in range(20):\n",
        "    # 1) erase previous gradients (if they exist)\n",
        "    opt.zero_grad()\n",
        "\n",
        "    # 2) make a prediction\n",
        "    pred = model(data)\n",
        "\n",
        "    # 3) calculate how much we missed\n",
        "    loss = ((pred - target)**2).sum()\n",
        "\n",
        "    # 4) figure out which weights caused us to miss\n",
        "    loss.backward()\n",
        "\n",
        "    # 5) change those weights\n",
        "    opt.step()\n",
        "\n",
        "    # 6) print our progress\n",
        "    print(loss.get().float_precision())\n",
        "   "
      ],
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([3.3130])\n",
            "tensor([0.6270])\n",
            "tensor([0.2930])\n",
            "tensor([0.1830])\n",
            "tensor([0.1190])\n",
            "tensor([0.0800])\n",
            "tensor([0.0510])\n",
            "tensor([0.0340])\n",
            "tensor([0.0230])\n",
            "tensor([0.0160])\n",
            "tensor([0.0120])\n",
            "tensor([0.0070])\n",
            "tensor([0.0040])\n",
            "tensor([0.0030])\n",
            "tensor([0.0020])\n",
            "tensor([0.0010])\n",
            "tensor([0.])\n",
            "tensor([0.0010])\n",
            "tensor([0.0010])\n",
            "tensor([0.])\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}